#+Title: Theorem Proving in Lean
#+Author: [[http://www.andrew.cmu.edu/user/avigad][Jeremy Avigad]], [[http://leodemoura.github.io][Leonardo de Moura]], [[http://www.cs.cmu.edu/~soonhok][Soonho Kong]]

# TODO: since there is more in init now, we no longer discuss import
# here. So we have to do it later.

* Dependent Type Theory
:PROPERTIES:
  :CUSTOM_ID: Dependent_Type_Theory
:END:

Dependent type theory is a powerful and expressive language, allowing
us to express complex mathematical assertions, write complex hardware
and software specifications, and reason about both of these in a
natural and uniform way. Lean is based on a version of dependent type
theory known as the /Calculus of Inductive Constructions/, with a
countable hierarchy of non-cumulative universes and inductive
types. By the end of this chapter, you will understand much of what
this means.

** Simple Type Theory

As a foundation for mathematics, set theory has a simple ontology that
is rather appealing. Everything is a set, including numbers,
functions, triangles, stochastic processes, and Riemannian
manifolds. It is a remarkable fact that one can construct a rich
mathematical universe from a small number of axioms that describe a
few basic set-theoretic constructions.

But for many purposes, including formal theorem proving, it is better
to have an infrastructure that helps us manage and keep track of the
various kinds of mathematical objects we are working with. "Type
theory" gets its name from the fact that every expression has an
associated /type/. For example, in a given context, =x + 0= may
denote a natural number and =f= may denote a function on the natural
numbers.

Here are some examples of how we can declare objects in Lean and
check their types.
#+BEGIN_SRC lean
/- declare some constants -/

constant m : nat        -- m is a natural number
constant n : nat
constants b1 b2 : bool  -- declare two constants at once

/- check their types -/

check m            -- output: nat
check n
check n + 0        -- nat
check m * (n + 0)  -- nat
check b1           -- bool
check b1 && b2     -- "&&" is boolean and
check b1 || b2     -- boolean or
check tt           -- boolean "true"

-- Try some examples of your own.

#+END_SRC

The =/-= and =-/= annotations indicate that the next line is a comment
block that is ignored by Lean. Similarly, two dashes indicate that the
rest of the line contains a comment that is also ignored. Comment
blocks can be nested, making it possible to "comment out" chunks of
code, just as in many programming languages.

The =constant= and =constants= commands introduce new constant symbols
into the working environment, and the =check= command asks Lean to
report their types. You should test this, and try typing some examples
of your own. Declaring new objects in this way is a good way to
experiment with the system, but it is ultimately undesirable: Lean is
a foundational system, which is to say, it provides us with powerful
mechanisms to /define/ all the mathematical objects we need, rather
than simply postulating them to the system. We will explore these
mechanisms in the chapters to come.

What makes simple type theory powerful is that one can build new types
out of others. For example, if =A= and =B= are types, =A → B= denotes
the type of functions from =A= to =B=, and =A × B= denotes the cartesian
product, that is, the type of ordered pairs consisting of an element
of =A= paired with an element of =B=.
#+BEGIN_SRC lean
constants m n : nat

constant f : nat → nat           -- type the arrow as "\to" or "\r"
constant f' : nat -> nat         -- alternative ASCII notation
constant f'' : ℕ → ℕ             -- \nat is alternative notation for nat
constant p : nat × nat           -- type the product as "\times"
constant q : prod nat nat        -- alternative notation
constant g : nat → nat → nat
constant g' : nat → (nat → nat)  -- has the same type as g!
constant h : nat × nat → nat

constant F : (nat → nat) → nat   -- a "functional"

check f               -- ℕ → ℕ
check f n             -- ℕ
check g m n           -- ℕ
check g m             -- ℕ → ℕ
check (m, n)          -- ℕ × ℕ
check p.1             -- ℕ
check p.2             -- ℕ
check (m, n).1        -- ℕ
check (p.1, n)        -- ℕ × ℕ
check F f             -- ℕ

-- Try it on your own: write down some types, declare some constants,
-- and check some expressions.

#+END_SRC

Let us dispense with some basic syntax. You can enter the unicode
arrow =→= by typing =\to= or "=\r=. You can also use the ASCII
alternative =->=, so that the expression =nat -> nat= and =nat → nat=
mean the same thing. Both expressions denote the type of functions
that take a natural number as input and return a natural number as
output. The symbol =ℕ= is alternative unicode notation for =nat=; you
can enter it by typing =\nat=. The unicode symbol =×= for the
cartesian product is entered =\prod=.

There are a few more things to notice here. First, the
application of a function =f= to a value =x= is denoted =f x=. Second,
when writing type expressions, arrows associate to the /right/; for
example, the type of =g= is =nat → (nat → nat)=. Thus we can view =g=
as a function that takes natural numbers and returns another function
that takes a natural number and returns a natural number. In type
theory, this is generally more convenient than writing =g= as a
function that takes a pair of natural numbers as input, and returns a
natural number as output. For example, it allows us to "partially
apply" the function =g=. The example above shows that =g m= has type
=nat → nat=, that is, the function that "waits" for a second argument,
=n=, and then returns =g m n=. Taking a function =h= of type =nat ×
nat → nat= and "redefining" it to look like =g= is a process known as
/currying/, something we will come back to below.

By now you may also have guessed that, in Lean, =(m, n)= denotes the
ordered pair of =m= and =n=, and if =p= is a pair, =fst p= and =snd p=
denote the two projections.

** Types as Objects

One way in which Lean's dependent type theory extends simple type
theory is that types themselves -- entities like =nat= and =bool= --
are first-class citizens, which is to say that they themselves are
objects of study. For that to be the case, each of them also has to
have a type.
#+BEGIN_SRC lean
check nat               -- Type
check bool              -- Type
check nat → bool        -- Type
check nat × bool        -- Type
check nat → nat         -- ...
check nat × nat → nat
check nat → nat → nat
check nat → (nat → nat)
check nat → nat → bool
check (nat → nat) → nat
#+END_SRC

We see that each one of the expressions above is an object of type
=Type=.  We can also declare new constants and constructors for types:
#+BEGIN_SRC lean
constants A B : Type
constant F : Type → Type
constant G : Type → Type → Type

check A        -- Type
check F A      -- Type
check F nat    -- Type
check G A      -- Type → Type
check G A B    -- Type
check G A nat  -- Type
#+END_SRC
Indeed, we have already seen an example of a function of type =Type →
Type → Type=, namely, the Cartesian product.
#+BEGIN_SRC lean
constants A B : Type

check prod A B       -- Type
check prod nat nat   -- Type
#+END_SRC
Here is another example: given any type =A=, the type =list A= denotes
the type of lists of elements of type =A=.
#+BEGIN_SRC lean
constant A : Type

check list A    -- Type
check list nat  -- Type
#+END_SRC

For those more comfortable with set-theoretic foundations, it may be
helpful to think of a type as nothing more than a set, in which case,
the elements of the type are just the elements of the set. Given that
every expression in Lean has a type, it is natural to ask: what type
does =Type= itself have?
#+BEGIN_SRC lean
check Type      -- Type₂
#+END_SRC
We have actually come up against one of the most subtle aspects of
Lean's typing system. Lean's underlying foundation has an infinite
hierarchy of types:
#+BEGIN_SRC lean
check Type 1   -- Type₂
check Type 2   -- Type₃
check Type 3   -- Type 4
check Type 4   -- Type 5
#+END_SRC
Think of =Type 1= as a universe of "small" or "ordinary" types.
=Type 2= is then a larger universe of types, which contains =Type 1= as an
element, and =Type 3= is an even larger universe of types, which
contains =Type 2= as an element. The list is indefinite, so that there
is a =Type n= for every natural number =n=. Lean introduces
abbreviations for the first three levels:
#+BEGIN_SRC lean
check Type    -- same as Type 1
check Type₂   -- same as Type 2
check Type₃   -- same as Type 3
#+END_SRC
It is rare to have to use more than those. There is also a =Type 0=,
which is also denoted =Prop=. This type has special properties, and
will be discussed in the next chapter.

We want some operations, however, to be /polymorphic/ over type
universes. For example, =list A= should make sense for any type =A=,
no matter which type universe =A= lives in. This explains the type
annotation of the function =list=:
#+BEGIN_SRC lean
check list    -- Type u_1 → Type (max 1 u_1)
#+END_SRC
Here =u_1= is a variable ranging over type levels. The output of the
=check= command means that whenever =A= has type =Type n=, =list A=
also has type =Type n= if =n= is at least 1, and has =Type 1= if =A=
has type =0=. The function =prod= is similarly polymorphic:
#+BEGIN_SRC lean
check prod    -- Type u_1 → Type u_2 → Type (max 1 u_1 u_2)
#+END_SRC
To define polymorphic constants and variables, Lean allows us to
declare universe variables explicitly:
#+BEGIN_SRC lean
universe variable u
constant A : Type u
check A
#+END_SRC
Throughout this book, you will see us do this in examples when we want
type constructions to have as much generality as possible. We will see
that the ability to treat type constructors as instances of ordinary
mathematical functions is a powerful feature of dependent type theory.

** Function Abstraction and Evaluation

We have seen that if we have =m n : nat=, then we have =(m, n) : nat
× nat=. This gives us a way of creating pairs of natural numbers.
Conversely, if we have =p : nat × nat=, then we have =fst p : nat= and
=snd p : nat=. This gives us a way of "using" a pair, by extracting its
two components.

We already know how to "use" a function =f : A → B=, namely, we can
apply it to an element =a : A= to obtain =f a : B=. But how do we
create a function from another expression?

The companion to application is a process known as "abstraction," or
"lambda abstraction." Suppose that by temporarily postulating a
variable =x : A= we can construct an expression =t : B=. Then the
expression =fun x : A, t=, or, equivalently, =λ x : A, t=, is an object
of type =A → B=. Think of this as the function from =A= to =B= which
maps any value =x= to the value =t=, which depends on =x=. For
example, in mathematics it is common to say "let =f= be the function
which maps any natural number =x= to =x + 5=." The expression =λ x :
nat, x + 5= is just a symbolic representation of the right-hand side
of this assignment.
#+BEGIN_SRC lean
check fun x : nat, x + 5
check λ x : nat, x + 5
#+END_SRC
Here are some more abstract examples:
#+BEGIN_SRC lean
constants A B  : Type
constants a1 a2 : A
constants b1 b2 : B

constant f : A → A
constant g : A → B
constant h : A → B → A
constant p : A → A → bool

check fun x : A, f x                      -- A → A
check λ x : A, f x                        -- A → A
check λ x : A, f (f x)                    -- A → A
check λ x : A, h x b1                     -- A → A
check λ y : B, h a1 y                     -- B → A
check λ x : A, p (f (f x)) (h (f a1) b2)  -- A → bool
check λ x : A, λ y : B, h (f x) y         -- A → B → A
check λ (x : A) (y : B), h (f x) y        -- A → B → A
check λ x y, h (f x) y                    -- A → B → A
#+END_SRC
Lean interprets the final three examples as the same expression; in
the last expression, Lean infers the type of =x= and =y= from the
types of =f= and =h=.

Be sure to try writing some expressions of your own. Some
mathematically common examples of operations of functions can be
described in terms of lambda abstraction:
#+BEGIN_SRC lean
constants A B C : Type
constant f : A → B
constant g : B → C
constant b : B

check λ x : A, x        -- A → A
check λ x : A, b        -- A → B
check λ x : A, g (f x)  -- A → C
check λ x, g (f x)

-- we can abstract any of the constants in the previous definitions

check λ b : B, λ x : A, x     -- B → A → A
check λ (b : B) (x : A), x    -- equivalent to the previous line
check λ (g : B → C) (f : A → B) (x : A), g (f x)
                              -- (B → C) → (A → B) → A → C
-- we can even abstract over the type

check λ (A B : Type) (b : B) (x : A), x
check λ (A B C : Type) (g : B → C) (f : A → B) (x : A), g (f x)
#+END_SRC

Think about what these expressions mean. The expression =λ x : A, x=
denotes the identity function on =A=, the expression =λ x : A, b=
denotes the constant function that always returns =b=, and =λ x : A, g
(f x)=, denotes the composition of =f= and =g=. We can, in general,
leave off the type annotations on the variable and let Lean infer it
for us. So, for example, we can write =λ x, g (f x)= instead of =λ x :
A, g (f x)=.

We can abstract over any of the constants in the previous definitions:
#+BEGIN_SRC lean
constants A B C : Type
constant f : A → B
constant g : B → C
constant b : B

-- BEGIN
check λ b : B, λ x : A, x     -- B → A → A
check λ (b : B) (x : A), x    -- B → A → A
check λ (g : B → C) (f : A → B) (x : A), g (f x)
                              -- (B → C) → (A → B) → A → C
-- END

check λ (A B : Type) (b : B) (x : A), x
check λ (A B C : Type) (g : B → C) (f : A → B) (x : A), g (f x)
#+END_SRC
Lean lets us combine lambdas, so the second example is equivalent to
the first. We can even abstract over the type:
#+BEGIN_SRC lean
constants A B C : Type
constant f : A → B
constant g : B → C
constant b : B

-- BEGIN
check λ (A B : Type) (b : B) (x : A), x
check λ (A B C : Type) (g : B → C) (f : A → B) (x : A), g (f x)
-- END
#+END_SRC
The last expression, for example, denotes the function that takes
three types, =A=, =B=, and =C=, and two functions, =g : B → C= and
=f : A → B=, and returns the composition of =g= and =f=. (Making sense
of the type of this function requires an understanding of dependent
products, which we will explain below.) Within a lambda expression =λ
x : A, t=, the variable =x= is a "bound variable": it is really a
placeholder, whose "scope" does not extend beyond =t=. For example,
the variable =b= in the expression =λ (b : B) (x : A), x= has nothing
to do with the constant =b= declared earlier. In fact, the expression
denotes the same function as =λ (u : B) (z : A), z=. Formally, the
expressions that are the same up to a renaming of bound variables are
called /alpha equivalent/, and are considered "the same." Lean
recognizes this equivalence.

Notice that applying a term =t : A → B= to a term =s : A= yields an
expression =t s : B=. Returning to the previous example and renaming
bound variables for clarity, notice the types of the following
expressions:
#+BEGIN_SRC lean
constants A B C : Type
constant f : A → B
constant g : B → C
constant h : A → A
constants (a : A) (b : B)

check (λ x : A, x) a                -- A
check (λ x : A, b) a                -- B
check (λ x : A, b) (h a)            -- B
check (λ x : A, g (f x)) (h (h a))  -- C

check (λ (v : B → C) (u : A → B) x, v (u x)) g f a   -- C

check (λ (Q R S : Type) (v : R → S) (u : Q → R) (x : Q),
        v (u x)) A B C g f a        -- C
#+END_SRC
As expected, the expression =(λ x : A, x) a= has type =A=. In fact,
more should be true: applying the expression =(λ x : A, x)= to =a=
should "return" the value =a=. And, indeed, it does:
#+BEGIN_SRC lean
constants A B C : Type
constant f : A → B
constant g : B → C
constant h : A → A
constants (a : A) (b : B)

eval (λ x : A, x) a                -- a
eval (λ x : A, b) a                -- b
eval (λ x : A, b) (h a)            -- b
eval (λ x : A, g (f x)) a          -- g (f a)

eval (λ (v : B → C) (u : A → B) x, v (u x)) g f a   -- g (f a)

eval (λ (Q R S : Type) (v : R → S) (u : Q → R) (x : Q),
       v (u x)) A B C g f a        -- g (f a)
#+END_SRC
The command =eval= tells Lean to /evaluate/ an expression. The process
of simplifying an expression =(λ x, t)s= to =t[s/x]= -- that is, =t=
with =s= substituted for the variable =x= -- is known as /beta
reduction/, and two terms that beta reduce to a common term are called
/beta equivalent/. But the =eval= command carries out other forms of
reduction as well:
#+BEGIN_SRC lean
constants m n : nat
constant b : bool

print "reducing pairs"
eval (m, n).1        -- m
eval (m, n).2        -- n

print "reducing boolean expressions"
eval tt && ff        -- ff
eval b && ff         -- ff

print "reducing arithmetic expressions"
eval n + 0           -- n
eval n + 2           -- succ (succ n)
eval 2 + 3           -- 5
#+END_SRC
In a later chapter, we will explain how these terms are evaluated. For
now, we only wish to emphasize that this is an important feature of
dependent type theory: every term has a computational behavior, and
supports a notion of reduction, or /normalization/. In principle, two
terms that reduce to the same value are called /definitionally
equal/. They are considered "the same" by the underlying logical
framework, and Lean does its best to recognize and support these
identifications.

** Introducing Definitions

As we have noted above, declaring constants in the Lean environment is
a good way to postulate new objects to experiment with, but most of
the time what we really want to do is /define/ objects in Lean
and prove things about them. The =definition= command provides one
important way of defining new objects.
#+BEGIN_SRC lean
definition foo : (ℕ → ℕ) → ℕ := λ f, f 0

check foo    -- ℕ
print foo    -- λ (f : ℕ → ℕ), f 0
#+END_SRC
We can omit the type when Lean has enough information to infer it:
#+BEGIN_SRC lean
definition foo' := λ f : ℕ → ℕ, f 0
#+END_SRC
The general form of a definition is ~definition foo : T := bar~. Lean
can usually infer the type =T=, but it is often a good idea to write
it explicitly. This clarifies your intention, and Lean will flag an
error if the right-hand side of the definition does not have the right
type.

Because function definitions are so common, Lean provides an
alternative notation, which puts the abstracted variables before the
colon and omits the lambda:
#+BEGIN_SRC lean
definition double (x : ℕ) : ℕ := x + x
print double
check double 3
eval double 3    -- 6

definition square (x : ℕ) := x * x
print square
check square 3
eval square 3    -- 9

definition do_twice (f : ℕ → ℕ) (x : ℕ) : ℕ := f (f x)

eval do_twice double 2    -- 8
#+END_SRC
These definitions are equivalent to the following:
#+BEGIN_SRC lean
definition double : ℕ → ℕ := λ x, x + x
definition square : ℕ → ℕ := λ x, x * x
definition do_twice : (ℕ → ℕ) → ℕ → ℕ := λ f x, f (f x)
#+END_SRC
We can even use this approach to specify arguments that are types:
#+BEGIN_SRC lean
definition compose (A B C : Type) (g : B → C) (f : A → B) (x : A) :
  C :=
g (f x)
#+END_SRC
As an exercise, we encourage you to use =do_twice= and =double= to
define functions that quadruple their input, and multiply the input
by 8. As a further exercise, we encourage you to try defining a
function
=Do_Twice : ((ℕ → ℕ) → (ℕ → ℕ)) → (ℕ → ℕ) → (ℕ → ℕ)=
which iterates /its/ argument twice, so that =Do_Twice do_twice= a
function which iterates /its/ input four times, and evaluate
=Do_Twice do_twice double 2=.

Above, we discussed the process of "currying" a function, that is,
taking a function =f (a, b)= that takes an ordered pair as an
argument, and recasting it as a function =f' a b= that takes two
arguments successively. As another exercise, we encourage you to
complete the following definitions, which "curry" and "uncurry" a
function.
#+BEGIN_SRC lean
definition curry (A B C : Type) (f : A × B → C) : A → B → C := sorry

definition uncurry (A B C : Type) (f : A → B → C) : A × B → C := sorry
#+END_SRC

** Local Definitions

Lean also allows you to introduce "local" definitions using the =let=
construct. The expression ~let a := t1 in t2~ is definitionally equal to
the result of replacing every occurrence of =a= in =t2= by =t1=.
#+BEGIN_SRC lean
check let y := 2 + 2 in y * y   -- ℕ
eval  let y := 2 + 2 in y * y   -- 16

definition t (x : ℕ) : ℕ :=
let y := x + x in y * y

eval t 2   -- 16
#+END_SRC
Here, =t= is definitionally equal to the term =(x + x) * (x + x)=.
You can combine multiple assignments in a single =let= statement:
#+BEGIN_SRC lean
check let y := 2 + 2, z := y + y in z * z   -- 16
eval  let y := 2 + 2, z := y + y in z * z   -- 64
#+END_SRC

Notice that the meaning of the expression ~let a := t1 in t2~ is very
similar to the meaning of =(λ a, t2) t1=, but the two are not the
same. In the first expression, you should think of every instance of
=a= in =t2= as a syntactic abbreviation for =t1=. In the second
expression, =a= is a variable, and the expression =λ a, t2= has to make
sense independently of the value of =a=. The =let= construct is a
stronger means of abbreviation, and there are expressions of the form
~let a := t1 in t2~ that cannot be expressed as =(λ a, t2) t1=. As an
exercise, try to understand why the definition of =foo= below type
checks, but the definition of =bar= does not.
#+BEGIN_SRC lean
definition foo := let a := nat  in λ x : a, x + 2

/-
definition bar := (λ a, λ x : a, x + 2) nat
-/
#+END_SRC

** Variables and Sections
:PROPERTIES:
  :CUSTOM_ID: Variables_and_Sections
:END:

This is a good place to introduce some organizational features of Lean
that are not a part of the axiomatic framework /per se/, but make it
possible to work in the framework more efficiently.

We have seen that the =constant= command allows us to declare new
objects, which then become part of the global context. Declaring new
objects in this way is somewhat crass. Lean enables us to /define/ all
of the mathematical objects we need, and /declaring/ new objects
willy-nilly is therefore somewhat lazy. In the words of Bertand
Russell, it has all the advantages of theft over honest toil. We will
see in the next chapter that it is also somewhat dangerous: declaring
a new constant is tantamount to declaring an axiomatic extension of
our foundational system, and may result in inconsistency.

So far, in this tutorial, we have used the =constant= command to
create "arbitrary" objects to work with in our examples. For example,
we have declared types =A=, =B=, and =C= to populate our context. This
can be avoided, using implicit or explicit lambda abstraction in our
definitions to declare such objects "locally":
#+BEGIN_SRC lean
definition compose (A B C : Type) (g : B → C) (f : A → B) (x : A) :
  C := g (f x)

definition do_twice (A : Type) (h : A → A) (x : A) : A := h (h x)

definition do_thrice (A : Type) (h : A → A) (x : A) : A := h (h (h x))
#+END_SRC
Repeating declarations in this way can be tedious, however. Lean
provides us with the =variable= and =variables= commands to make such
declarations look global:
#+BEGIN_SRC lean
variables (A B C : Type)

definition compose (g : B → C) (f : A → B) (x : A) : C := g (f x)
definition do_twice (h : A → A) (x : A) : A := h (h x)
definition do_thrice (h : A → A) (x : A) : A := h (h (h x))
#+END_SRC
We can declare variables of any type, not just =Type= itself:
#+BEGIN_SRC lean
variables (A B C : Type)
variables (g : B → C) (f : A → B) (h : A → A)
variable x : A

definition compose := g (f x)
definition do_twice := h (h x)
definition do_thrice := h (h (h x))

print compose
print do_twice
print do_thrice
#+END_SRC
Printing them out shows that all three groups of definitions have
exactly the same effect.

The =variable= and =variables= commands look like the =constant= and
=constants= commands we have used above, but there is an important
difference: rather than creating permanent entities, the declarations
simply tell Lean to insert the variables as bound variables in
definitions that refer to them. Lean is smart enough to figure out
which variables are used explicitly or implicitly in a definition. We
can therefore proceed as though =A=, =B=, =C=, =g=, =f=, =h=, and =x=
are fixed objects when we write our definitions, and let Lean abstract
the definitions for us automatically.

When declared in this way, a variable stays in scope until the end of
the file we are working on, and we cannot declare another variable
with the same name. Sometimes, however, it is useful to limit the
scope of a variable. For that purpose, Lean provides the notion of a
=section=:
#+BEGIN_SRC lean
section useful
  variables (A B C : Type)
  variables (g : B → C) (f : A → B) (h : A → A)
  variable x : A

  definition compose := g (f x)
  definition do_twice := h (h x)
  definition do_thrice := h (h (h x))
end useful
#+END_SRC
When the section is closed, the variables go out of scope, and become
nothing more than a distant memory.

You do not have to indent the lines within a section, since Lean
treats any blocks of returns, spaces, and tabs equivalently as
whitespace. Nor do you have to name a section, which is to say, you
can use an anonymous =section= / =end= pair. If you do name a section,
however, you have to close it using the same name. Sections can also
be nested, which allows you to declare new variables incrementally.

** Namespaces
:PROPERTIES:
  :CUSTOM_ID: Namespaces
:END:

Lean provides us with the ability to group definitions, notation, and
other information into nested, hierarchical /namespaces/:
#+BEGIN_SRC lean
namespace foo
  definition a : ℕ := 5
  definition f (x : ℕ) : ℕ := x + 7

  definition fa : ℕ := f a
  definition ffa : ℕ := f (f a)

  print "inside foo"

  check a
  check f
  check fa
  check ffa
  check foo.fa
end foo

print "outside the namespace"

-- check a  -- error
-- check f  -- error
check foo.a
check foo.f
check foo.fa
check foo.ffa

open foo

print "opened foo"

check a
check f
check fa
check foo.fa
#+END_SRC
When we declare that we are working in the namespace =foo=, every
identifier we declare has a full name with prefix "=foo.=" Within the
namespace, we can refer to identifiers by their shorter names, but
once we end the namespace, we have to use the longer names.

The =open= command brings the shorter names into the current
context. Often, when we import a theory file, we will want to open one or
more of the namespaces it contains, to have access to the short
identifiers, notations, and so on. But sometimes we will want to leave
this information hidden, for example, when they conflict with
identifiers and notations in another namespace we want to use. Thus
namespaces give us a way to manage our working environment.

For example, Lean groups definitions and theorems involving lists into
a namespace =list=.
#+BEGIN_SRC lean
check list.nil
check list.cons
check list.append
#+END_SRC
We will discuss their types, below. The command =open list= allows us
to use the shorter names:
#+BEGIN_SRC lean
open list

check nil
check cons
check append
#+END_SRC

Like sections, namespaces can be nested:
#+BEGIN_SRC lean
namespace foo
  definition a : ℕ := 5
  definition f (x : ℕ) : ℕ := x + 7

  definition fa : ℕ := f a

  namespace bar
    definition ffa : ℕ := f (f a)

    check fa
    check ffa
  end bar

  check fa
  check bar.ffa
end foo

check foo.fa
check foo.bar.ffa

open foo

check fa
check bar.ffa
#+END_SRC
Namespaces that have been closed can later be reopened, even in
another file:
#+BEGIN_SRC lean
namespace foo
  definition a : ℕ := 5
  definition f (x : ℕ) : ℕ := x + 7

  definition fa : ℕ := f a
end foo

check foo.a
check foo.f

namespace foo
  definition ffa : ℕ := f (f a)
end foo
#+END_SRC
Like sections, nested namespaces have to be closed in the order they
are opened. Also, a namespace cannot be opened within a section;
namespaces have to live on the outer levels.

Namespaces and sections serve different purposes: namespaces organize
data and sections declare variables for insertion in theorems. A
namespace can be viewed as a special kind of section, however. In
particular, if you use the =variable= command within a namespace, its
scope is limited to the namespace. Similarly, if you use an =open=
command within a namespace, its effects disappear when the namespace
is closed.

As scoping mechanisms, namespaces and sections govern more than just
variables and identifier names. We will later see that notations
defined in a namespace are operant only when the namespace is open,
and notation defined in a section has scope limited to the
section. Similarly, if we use the =open= command inside a section or
namespace, it only remains in effect until that section or namespace
is closed. As a result, namespaces and sections provide useful ways of
managing the background context while we work with Lean.

** Dependent Types
:PROPERTIES:
  :CUSTOM_ID: Dependent_Types
:END:

You now have rudimentary ways of defining functions and objects in Lean,
and we will gradually introduce you to many more. Our ultimate goal in
Lean is to /prove/ things about the objects we define, and the next
chapter will introduce you to Lean's mechanisms for stating theorems
and constructing proofs. Meanwhile, let us remain on the topic of
defining objects in dependent type theory for just a moment longer,
in order to explain what makes dependent type theory /dependent/, and
why that is useful.

The short explanation is that what makes dependent type theory
dependent is that types can depend on parameters. You have already
seen a nice example of this: the type =list A= depends on the argument
=A=, and this dependence is what distinguishes =list ℕ= and =list
bool=. For another example, consider the type =vec A n=, the type of
vectors of elements of =A= of length =n=. This type depends on /two/
parameters: the type =A : Type= of the elements in the vector and the
length =n : ℕ=.

Suppose we wish to write a function =cons= which inserts a new element
at the head of a list. What type should =cons= have? Such a function
is /polymorphic/: we expect the =cons= function for =ℕ=, =bool=, or
an arbitrary type =A= to behave the same way. So it makes sense to
take the type to be the first argument to =cons=, so that for any
type, =A=, =cons A= is the insertion function for lists of type
=A=. In other words, for every =A=, =cons A= is the function that
takes an element =a : A= and a list =l : list A=, and returns a new
list, so we have =cons A a l : list A=.

It is clear that =cons A= should have type =A → list A → list A=. But
what type should =cons= have? A first guess might be =Type → A → list
A → list A=, but, on reflection, this does not make sense: the =A= in
this expression does not refer to anything, whereas it should refer to
the argument of type =Type=. In other words, /assuming/ =A : Type= is
the first argument to the function, the type of the next two elements
are =A= and =list A=. These types vary depending on the first
argument, =A=.

This is an instance of a /Pi type/ in dependent type theory. Given
=A : Type= and =B : A → Type=, think of =B= as a family of types over
=A=, that is, a type =B a= for each =a : A=. In that case, the type
=Π x : A, B x= denotes the type of functions =f= with the property
that, for each =a : A=, =f a= is an element of =B a=. In other words,
the type of the value returned by =f= depends on its input.

Notice that =Π x : A, B= makes sense for any expression =B :
Type=. When the value of =B= depends on =x= (as does, for example, the
expression =B x= in the previous paragraph), =Π x : A, B= denotes a
dependent function type. When =B= doesn't depend on =x=, =Π
x : A, B= is no different from the type =A → B=. Indeed, in dependent
type theory (and in Lean), the Pi construction is fundamental, and =A
→ B= is nothing more than notation for =Π x : A, B= when =B= does not
depend on =A=.

Returning to the example of lists, we can model some basic list
operations as follows. We use =namespace hide= to avoid a naming conflict
with the =list= type defined in the standard library.
# TODO: where?
#+BEGIN_SRC lean
namespace hide

universe variable u

constant list : Type u → Type u

constant cons : Π A : Type u, A → list A → list A
constant nil : Π A : Type u, list A
constant head : Π A : Type u, list A → A
constant tail : Π A : Type u, list A → list A
constant append : Π A : Type u, list A → list A → list A

end hide
#+END_SRC
You can enter the symbol =Π= by typing =\Pi=. Here, =nil= is intended
to denote the empty list, =head= and =tail= return the first element
of a list and the remainder, respectively. The constant =append= is
intended to denote the function that concatenates two lists.

We emphasize that these constant declarations are only for the
purposes of illustration. The =list= type and all these operations
are, in fact, /defined/ in Lean's standard library, and are proved to
have the expected properties. In fact, as the next example shows, the
types indicated above are essentially the types of the objects that
are defined in the library. (We will explain the =@= symbol and the
difference between the round and curly brackets momentarily.)
#+BEGIN_SRC lean
open list

check list     -- Type u_1 → Type u_1

check @cons    -- Π {A : Type u_1}, A → list A → list A
check @nil     -- Π {A : Type u_1}, list A
check @head    -- Π {A : Type u_1} [_inst_1 : inhabited A], list A → A
check @tail    -- Π {A : Type u_1}, list A → list A
check @append  -- Π {A : Type u_1}, list A → list A → list A
#+END_SRC
There is a subtlety in the definition of =head=: the type =A= is
required to have at least one element, and when passed the
empty list, the function must determine a default element of the
relevant type. We will explain how this is done in a later chapter.
# TODO: add this reference when the chapter is restored
# We will explain how this is done in Chapter [[file:09_Type_Classes.org::#Type_Classes][Type Classes]].

Vector operations are handled similarly:
#+BEGIN_SRC lean
universe variable u
constant vec : Type u → ℕ → Type u

namespace vec
  constant empty : Π A : Type u, vec A 0
  constant cons :
    Π (A : Type u) (n : ℕ), A → vec A n → vec A (n + 1)
  constant append :
    Π (A : Type u) (n m : ℕ),  vec A m → vec A n → vec A (n + m)
end vec
#+END_SRC

In the coming chapters, you will come across many instances of
dependent types. Here we will mention just one more important and
illustrative example, the /Sigma types/, =Σ x : A, B x=, sometimes
also known as /dependent pairs/. These are, in a sense, companions to
the Pi types. The type =Σ x : A, B x= denotes the type of pairs
=sigma.mk a b= where =a : A= and =b : B a=.
# TODO: where to discuss this? The angle brackets only work where
#   the expected type is known.
# You can also use angle
# brackets =<a, b>= as notation for =sigma.mk a b=. (To type these
# brackets, use the shortcuts =\<= and =\>=.)
Just as Pi types =Π x : A, B x= generalize the notion of a function
type =A → B= by allowing =B= to depend on =A=, Sigma types =Σ x : A, B
x= generalize the cartesian product =A × B= in the same way: in the
expression =sigma.mk a b=, the type of the second element of the pair,
=b : B a=, depends on the first element of the pair, =a : A=.
#+BEGIN_SRC lean
variable A : Type
variable B : A → Type
variable a : A
variable b : B a

check sigma.mk a b   -- Σ (a : A), B a
check (sigma.mk a b).1  -- A
check (sigma.mk a b).2  -- B (sigma.fst (sigma.mk a b))

eval  (sigma.mk a b).1  -- a
eval  (sigma.mk a b).2  -- b
#+END_SRC
Notice that when =p= is a dependent pair the expressions =(sigma.mk a b).1= and
=(sigma.mk a b).2= are short for =sigma.fst (sigma.mk a b)= and =sigma.snd
(sigma.mk a b)=, respectively, and that these reduce to =a= and =b=,
respectively.

** Implicit Arguments
:PROPERTIES:
  :CUSTOM_ID: Implicit_Arguments
:END:

Suppose we have an implementation of lists as described above.
#+BEGIN_SRC lean
namespace hide
universe variable u
constant list : Type u → Type u

namespace list
  constant cons : Π A : Type u, A → list A → list A
  constant nil : Π A : Type u, list A
  constant append : Π A : Type u, list A → list A → list A
end list
end hide
#+END_SRC
Then, given a type =A=, some elements of =A=, and some lists of
elements of =A=, we can construct new lists using the constructors.
#+BEGIN_SRC lean
namespace hide
universe variable u
constant list : Type u → Type u

namespace list
  constant cons : Π A : Type u, A → list A → list A
  constant nil : Π A : Type u, list A
  constant append : Π A : Type u, list A → list A → list A
end list

-- BEGIN
open hide.list

variable  A : Type
variable  a : A
variables l1 l2 : list A

check cons A a (nil A)
check append A (cons A a (nil A)) l1
check append A (append A (cons A a (nil A)) l1) l2
-- END
end hide
#+END_SRC

Because the constructors are polymorphic over types, we have to insert
the type =A= as an argument repeatedly. But this information is
redundant: one can infer the argument =A= in =cons A a (nil A)= from
the fact that the second argument, =a=, has type =A=. One can
similarly infer the argument in =nil A=, not from anything else in
that expression, but from the fact that it is sent as an argument to
the function =cons=, which expects an element of type =list A= in that
position.

This is a central feature of dependent type theory: terms carry a lot
of information, and often some of that information can be inferred
from the context. In Lean, one uses an underscore, =_=, to specify
that the system should fill in the information automatically. This is
known as an "implicit argument."
#+BEGIN_SRC lean
namespace hide
universe variable u
constant list : Type u → Type u

namespace list
  constant cons : Π A : Type u, A → list A → list A
  constant nil : Π A : Type u, list A
  constant append : Π A : Type u, list A → list A → list A
end list

open hide.list

variable  A : Type
variable  a : A
variables l1 l2 : list A

-- BEGIN
check cons _ a (nil _)
check append _ (cons _ a (nil _)) l1
check append _ (append _ (cons _ a (nil _)) l1) l2
-- END
end hide
#+END_SRC

It is still tedious, however, to type all these underscores.  When a
function takes an argument that can generally be inferred from
context, Lean allows us to specify that this argument should, by
default, be left implicit. This is done by putting the arguments in
curly braces, as follows:
#+BEGIN_SRC lean
namespace hide
universe variable u
constant list : Type u → Type u

-- BEGIN
namespace list
  constant cons : Π {A : Type u}, A → list A → list A
  constant nil : Π {A : Type u}, list A
  constant append : Π {A : Type u}, list A → list A → list A
end list

open hide.list

variable  A : Type
variable  a : A
variables l1 l2 : list A

check cons a nil
check append (cons a nil) l1
check append (append (cons a nil) l1) l2
-- END
end hide
#+END_SRC
All that has changed are the braces around =A : Type u= in the
declaration of the variables. We can also use this device in function
definitions:
#+BEGIN_SRC lean
universe variable u
definition ident {A : Type u} (x : A) := x

variables A B : Type u
variables (a : A) (b : B)

check ident      -- ?M_1 → ?M_1
check ident a    -- A
check ident b    -- B
#+END_SRC
This makes the first argument to =ident= implicit. Notationally, this
hides the specification of the type, making it look as though =ident=
simply takes an argument of any type. In fact, the function =id= is
defined in the standard library in exactly this way. We have chosen
a nontraditional name here only to avoid a clash of names.

# TODO: pp.metavar_args is gone. What to say about this?

# In the first =check= command, the inscription =?A= indicates that the
# type of =ident= depends on a "placeholder," or "metavariable," that
# should, in general, be inferred from the context. The output of the
# second =check= command is somewhat verbose: it indicates that the
# placeholder, =?A=, can itself depend on any of the variables =A=, =B=,
# =a=, and =b= that are in the context. If this additional information
# is annoying, you can suppress it by writing =@ident=, as described
# below. Alternatively, you can set an option to avoid printing these
# arguments:
# #+BEGIN_SRC lean
# definition ident {A : Type} (x : A) := x

# -- BEGIN
# variables A B : Type
# variables (a : A) (b : B)

# set_option pp.metavar_args true
# check ident      -- ?A → ?A
# -- END
# #+END_SRC

Variables can also be declared implicit when they are declared with
the =variables= command:
#+BEGIN_SRC lean
universe variable u

section
  variable {A : Type u}
  variable x : A
  definition ident := x
end

variables A B : Type u
variables (a : A) (b : B)

check ident
check ident a
check ident b
#+END_SRC
This definition of =ident= has the same effect as the one above.

Lean has very complex mechanisms for instantiating implicit arguments,
and we will see that they can be used to infer function types,
predicates, and even proofs. The process of instantiating these
"holes," or "placeholders," in a term is often known as
/elaboration/. The presence of implicit arguments means that at times
there may be insufficient information to fix the meaning of an
expression precisely. An expression like =id= or =list.nil= is said to
be /polymorphic/, because it can take on different meanings in
different contexts. One can always specify the type =T= of an
expression =e= by writing =(e : T)=. This instructs Lean's elaborator
to use the value =T= as the type of =e= when trying to resolve
implicit arguments. The second pair of examples below use this
mechanism to specify the desired types of the expressions =id= and
=list.nil=:
#+BEGIN_SRC lean
check list.nil             -- list ?M1
check id                   -- ?M1 → ?M1

check (list.nil : list ℕ)  -- list ℕ
check (id : ℕ → ℕ)         -- ℕ → ℕ
#+END_SRC

Numerals are overloaded in Lean, but when the type of a numeral cannot
be inferred, Lean assumes, by default, that it is a natural number. So
the expressions in the first two =check= commands are elaborated in
the same way, whereas the third =check= command interprets =2= as a
raw numeral.
#+BEGIN_SRC lean
check 2            -- ℕ
check (2 : ℕ)      -- ℕ
check (2 : num)    -- num
#+END_SRC

# TODO: what to say about this?
# As this
# tutorial progresses, we will gradually learn more about what Lean's
# powerful elaborator can do, and we will discuss the elaborator in
# depth in Chapter [[file:08_Building_Theories_and_Proofs.org::#Elaboration_and_Unification][Elaboration and Unification]].

Sometimes, however, we may find ourselves in a situation where we have
declared an argument to a function to be implicit, but now want to
provide the argument explicitly. If =foo= is such a function, the
notation =@foo= denotes the same function with all the arguments made
explicit.
#+BEGIN_SRC lean
variables A B : Type
variables (a : A) (b : B)

-- BEGIN
check @id        -- Π {A : Type u_1}, A → A
check @id A      -- A → A
check @id B      -- B → B
check @id A a    -- A
check @id B b    -- B
-- END
#+END_SRC
Notice that now the first =check= command gives the type of the
identifier, =id=, without inserting any placeholders. Moreover, the
output indicates that the first argument is implicit.
